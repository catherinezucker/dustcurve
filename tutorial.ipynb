{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics\n",
    "\n",
    "We are going to use parallel-tempering, implemented via the python emcee package, to explore our posterior, which consists of the set of distances to the twelve velocity slices. Since we need to explore a twelve dimensional parameter space, we are going to use 50 walkers, 500 steps each, at 5 different temperatures. If you would like to edit this parameters, simply edit \"nwalkers\", \"ntemps\", and \"nsteps\" in the cell below. However, we are only going to keep the lowest temperature chain ($\\beta=1$) for analysis. Since the sampler.chain object from PTSampler returns an array of shape (Ntemps, Nwalkers, Nsteps, Ndim), returning the samples for all walkers, steps, and dimensions at $\\beta=1$ would correspond to sampler.chain[0,:,:,:]. To decrease your value of $\\beta$ simply increase the index for the first dimension. For more information on how PTSampler works, see http://dan.iel.fm/emcee/current/user/pt/. We will set off our walkers in a ball around the kinematic distance estimates for the Cepheus molecular cloud given by a flat rotation curve from Leroy & Rosolowsky 2006. You can edit the starting positions of the walkers by editing the \"result\" variable below.  \n",
    "\n",
    "### Setting up the positional arguments for PTSampler\n",
    "\n",
    "We need to feed PTSampler the required positional arguments for the log_likelihood and log_prior function. We do this using the fetch_args function from the io module, which creates an instance of the pixclass object that holds our data and metadata. Fetch_args accepts three arguments: \n",
    "\n",
    "- A string specifiying the h5 filename containing your data, in our case 89996.h5\n",
    "- The prior bounds you want to impose on the distances (flat prior), in units of distance modulus. This is given as a list in the format [lowerbound, upperbound]. This must be between 4 and 19, because that's the distance modulus range of our stellar posterior array. \n",
    "- The gas-to-dust coefficient you'd like to use, given as a float; for this tutorial, we are pulling a value from the literature of 0.06 magnitudes/K. \n",
    "\n",
    "Fetch_args will then return the correct arguments for the log_likelihood and log_prior functions within the model module. \n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stars used in analysis: 3065\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ab5f1be76fc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#burn in, and save final positions for all parameters, which we'll then set off our walkers at for the \"real\" thing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mpost_burn_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstarting_positions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/n/home12/czucker/envs/PYTHON3/lib/python3.4/site-packages/emcee/sampler.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[1;34m(self, pos0, N, rstate0, lnprob0, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m    156\u001b[0m         for results in self.sample(pos0, lnprob0, rstate0, iterations=N,\n\u001b[1;32m--> 157\u001b[1;33m                                    **kwargs):\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/n/home12/czucker/envs/PYTHON3/lib/python3.4/site-packages/emcee/ptsampler.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, p0, lnprob0, lnlike0, iterations, thin, storechain)\u001b[0m\n\u001b[0;32m    255\u001b[0m                              self.logpargs, self.loglkwargs, self.logpkwargs)\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/n/home12/czucker/envs/PYTHON3/lib/python3.4/site-packages/emcee/ptsampler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogpargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogpkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/n/home12/czucker/dustcurve/dustcurve/model.py\u001b[0m in \u001b[0;36mlog_prior\u001b[1;34m(theta, bounds)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m#check that coefficients (second half of theta array) are within acceptable bounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "import emcee\n",
    "from dustcurve import model\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from dustcurve import pixclass\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from dustcurve import io\n",
    "from dustcurve import hputils\n",
    "from dustcurve import kdist\n",
    "%matplotlib inline\n",
    "\n",
    "#this code pulls snippets from the PHYS201 week 9 MCMC notebook written by Vinny Manohoran and the PHYS201 L9 solutions,\n",
    "#written by Tom Dimiduk and Kevin Shain\n",
    "\n",
    "#suppress obnoxious deprecation warning that doesn't affect output\n",
    "warnings.filterwarnings(\"ignore\", category=Warning, module=\"emcee\")\n",
    "\n",
    "fnames='89996.h5'\n",
    "\n",
    "#fetch the required likelihood and prior arguments for PTSampler\n",
    "ldata,pdata=io.fetch_args(fnames,[4,19],0.06)\n",
    "\n",
    "# the model has 12 parameters; we'll use 50 walkers, 500 steps each, at 5 different temps\n",
    "ndim=24\n",
    "nslices=12\n",
    "nwalkers = 50\n",
    "nsteps = 500\n",
    "ntemps=5\n",
    "\n",
    "#setting off the walkers at the kinematic distance given by the literature, assuming a flat rotation curve, theta=220 km/s, R=8.5 kpc\n",
    "#Details on rotation curve given in Rosolowsky and Leroy 2006\n",
    "vslices=np.linspace(-15.6,-1.3,12)\n",
    "klong=np.ones(12)*109.5\n",
    "klat=np.ones(12)*13.5\n",
    "kdist=kdist.kdist(klong,klat,vslices)\n",
    "kdistmod=5*np.log10(kdist)-5\n",
    "\n",
    "#slightly perturb the starting positions for each walker, in a ball centered around result\n",
    "result=kdistmod.tolist()\n",
    "result.extend(0.06 for i in range (nslices))\n",
    "starting_positions = [[result + 1e-1*np.random.randn(ndim) for i in range(nwalkers)] for j in range(ntemps)]\n",
    "\n",
    "#set up the starting position array and add variance (up to 1 in distance modulus) to each walker \n",
    "starting_positions = [[result + 1e-1*np.random.randn(ndim) for i in range(nwalkers)] for j in range(ntemps)]\n",
    "\n",
    "#set up the sampler object\n",
    "sampler = emcee.PTSampler(ntemps, nwalkers, ndim, model.log_likelihood, model.log_prior, loglargs=(ldata), logpargs=[pdata])\n",
    "\n",
    "#burn in, and save final positions for all parameters, which we'll then set off our walkers at for the \"real\" thing\n",
    "post_burn_pos, prob, state = sampler.run_mcmc(starting_positions, 100)\n",
    "sampler.reset()\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the sampler and time how long it takes\n",
    "%time sampler.run_mcmc(post_burn_pos, nsteps)\n",
    "print('Sampler Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampler is done running, so now let's check out the results. We are going to print out our mean acceptance fraction across all walkers for the coldest temperature chain. \n",
    "\n",
    "We are going to discard the first 300 steps of each chain as burn-off; to change the number of steps to burn off, simply edit the 3rd dimension of sampler.chain[0,:,n:,:] and input your desired value of n. Next we are going to plot what the chains look like, for each distance parameter and for the first ten walkers. The chains should all be reasonably well-mixed. Finally, we are going to compute and print out the 50th, 16th, and 84th percentile of chain for each distance parameter, using the \"quantile\" attribute of a pandas dataframe object (in our case \"parameter_samples\"). The 50th percentile measurement represents are best guess for the each distance parameter, while the 16th and 84th percentile parameter give us a sense of the uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract the coldest [beta=1] temperature chain from the sampler object; discard first 100 samples as burnin\n",
    "samples_cold = sampler.chain[0,:,100:,:]\n",
    "traces_cold = samples_cold.reshape(-1, ndim).T\n",
    "\n",
    "#check out acceptance fraction:\n",
    "print(\"Our mean acceptance fraction for the coldest chain is %.2f\" % np.mean(sampler.acceptance_fraction[0]))\n",
    "\n",
    "unique_co,indices,post_array,ratio=ldata\n",
    "\n",
    "#find best fit values for each of the 24 parameters (12 d's and 12 c's)\n",
    "theta=pd.DataFrame(traces_cold)\n",
    "quantile_50=theta.quantile(.50, axis=1).values\n",
    "quantile_85=theta.quantile(.85, axis=1).values\n",
    "quantile_16=theta.quantile(.16, axis=1).values\n",
    "\n",
    "#print out distances\n",
    "for i in range(0,len(best)/2):\n",
    "    print('d%i: %.3f + %.3f - %.3f' % (i,quantile_50[i],quantile_85[i], quantile_16[i]))\n",
    "\n",
    "#print out coefficients\n",
    "for i in range(len(theta)/2, len(theta)):\n",
    "    print('d%i: %.3f + %.3f - %.3f' % (i,quantile_50[i],quantile_85[i], quantile_16[i]))\n",
    "    \n",
    "\n",
    "\n",
    "#plot the reddening profile over the stacked, normalized stellar posterior surfaces    \n",
    "plot_posterior.plot_posterior(post_array,np.linspace(4,19,120),np.linspace(0,7,700),quantile_50,ratio,unique_co)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "#Save the results of the sampler:\n",
    "output=fnames\n",
    "\n",
    "fwrite = h5py.File(\"/n/fink1/czucker/Output/\"+str(output), \"w\")\n",
    "chaindata = fwrite.create_dataset(\"/chains\", sampler.chain.shape, dtype='f')\n",
    "chaindata[:,:,:,:]=sampler.chain\n",
    "    \n",
    "probdata = fwrite.create_dataset(\"/probs\", sampler.lnprobability.shape, dtype='f')\n",
    "probdata[:,:,:]=sampler.lnprobability\n",
    "\n",
    "\n",
    "fwrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
